{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4e0a66-4373-46e1-9f71-a9ad93c432bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df70076-bc77-445b-9f00-2c292bdd89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the config file in the same directory as the analysis script\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1074de-f7b8-4748-b3f4-7cdf62bb64b4",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803fc9c-5b1d-49f5-b8bf-9b450a1b6217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters set in this notebook\n",
    "# If any of these are contained in the config they will be overwritten\n",
    "pm = {\n",
    "    # Max number of articles to retrieve\n",
    "    'n_articles': 100000,\n",
    "    \n",
    "    # We toss anything below these as irrelevant\n",
    "    'required_rank': 5,\n",
    "    'required_mentions': 0,\n",
    "    \n",
    "    # Columns from which to compile text\n",
    "    'text_columns': [ 'abstract', 'lead_paragraph', 'snippet', 'headline.main', ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18adc45-39c9-42d9-9efd-1f04beff4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update with global parameters\n",
    "pm.update( config.pm )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12100185-1f6b-414f-a299-4c5dd647ff48",
   "metadata": {},
   "source": [
    "# New York Times data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb1cec-87a1-4afa-bede-adfc61f4f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynytimes import NYTAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb734e26-200a-4f2e-92a5-d116f7e2f990",
   "metadata": {},
   "source": [
    "## Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f82e6d-e04f-4cf0-8107-e7ac37ec838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nytapi = NYTAPI( os.environ.get( 'NYTIMES_KEY' ), parse_dates=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce016f-faee-4ad9-b49c-491d44fe8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a prompt for the API\n",
    "filter_query_prompt = ''\n",
    "for i, organization in enumerate( pm['organizations'] ):\n",
    "    if i != 0:\n",
    "        filter_query_prompt += ' OR '\n",
    "    filter_query_prompt += 'organizations:(\"{}\")'.format( organization )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b53b17-cb58-4917-900c-85d6c72004d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all results\n",
    "all_results = nytapi.article_search(\n",
    "    query='',\n",
    "    results=pm['n_articles'],\n",
    "    dates={ 'begin':pm['start_date'], 'end':pm['end_date'] },\n",
    "    options={\n",
    "        'fq': filter_query_prompt,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7468a3-be14-458f-8c5d-f3f4d66bcbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Retrieved {} results'.format( len( all_results ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee387c0-d268-4c60-bef8-8435c12f854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter on organization rank\n",
    "results = []\n",
    "ranks = []\n",
    "for result in all_results:\n",
    "    \n",
    "    append_result = False\n",
    "    rank = np.inf\n",
    "    for keyword in result['keywords']:\n",
    "        is_relevant = (\n",
    "            ( keyword['value'] in pm['organizations'] )\n",
    "            and ( keyword['name'] == 'organizations' )\n",
    "            and ( keyword['rank'] <= pm['required_rank'] )\n",
    "        )\n",
    "        if is_relevant:\n",
    "            append_result = True\n",
    "\n",
    "            # Keep the lowest (most-relevant) rank\n",
    "            if keyword['rank'] < rank:\n",
    "                rank = keyword['rank']\n",
    "\n",
    "    if append_result:\n",
    "        results.append( result )\n",
    "        ranks.append( rank )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defcb52e-9b53-41ff-887b-ab8b7f4d66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Filtered down to {} retrieved results'.format( len( results ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3a5d7-56f2-49aa-9663-77dbcdee3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create storage dictionary\n",
    "nyt_data = {\n",
    "    'pub_date': [],\n",
    "    'word_count': [],\n",
    "    'type_of_material': [],\n",
    "    '_id': [],\n",
    "}\n",
    "for column in pm['text_columns']:\n",
    "    nyt_data[column] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504efb80-9884-42bf-b558-02b767e68ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect\n",
    "for i, result in enumerate( results ):\n",
    "    for column in nyt_data.keys():\n",
    "        \n",
    "        # Parse column\n",
    "        if '.' in column:\n",
    "            column_keys = column.split( '.' )\n",
    "            column_val = result[column_keys[0]][column_keys[1]]\n",
    "        else:\n",
    "            column_val = result[column]\n",
    "            \n",
    "        # Store\n",
    "        nyt_data[column].append( column_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0242f108-2667-488b-a92d-70f115d0317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into a dataframe\n",
    "nyt = pd.DataFrame( nyt_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c2561-8ebd-4d58-a114-2b0122ae51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the full string\n",
    "nyt['text'] = ( nyt[pm['text_columns']] + ' ' ).sum( axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec0b78-45b7-4cf6-a30a-280c3eb01de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store relvancy\n",
    "nyt['relevance_rank'] = ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca137ff-41e2-4bfb-93f9-7bc32353cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364b88d-83eb-43cd-9549-24a017688b88",
   "metadata": {},
   "source": [
    "## Filter data\n",
    "Some of the text columns don't mention google *enough* times. This portion of the notebook removes those rows.\n",
    "\n",
    "We need to import the library in the cell below in order to use the word_count function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a23f01-b3f4-4ee4-9f92-661f5e1c8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcea7a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7615be-b8a7-4a16-acfd-ca949c00ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count keyword mentions\n",
    "inds_to_drop = []\n",
    "keyword_counts = []\n",
    "for i in range (len(nyt['text'])):\n",
    "    blob = TextBlob(nyt.loc[i,'text'])\n",
    "    keyword_count = blob.word_counts[pm['keyword']]\n",
    "    keyword_counts.append( keyword_count )\n",
    "    if keyword_count < pm['required_mentions']:\n",
    "        inds_to_drop.append( i )\n",
    "nyt['keyword_counts'] = keyword_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbbfbe1-20ea-4bcb-87c0-371077d3c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop keywords with an insufficient number of mentions\n",
    "nyt.drop( inds_to_drop, inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38011d69-cded-429c-994d-ac75d3d6e32e",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c7b06-05de-4af1-af74-10e47dcdcc2c",
   "metadata": {},
   "source": [
    "### TextBlob\n",
    "Here, we are using textblob as our sentiment analysis tool. We are taking data from the text column of the data frame and outputting both polarity and subjectivity for each article. At the end, we are combining it into one single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_vec = []\n",
    "subj_vec = []\n",
    "for i in range (len(nyt['text'])):\n",
    "    blob = TextBlob(nyt['text'][i])\n",
    "    pol = blob.sentiment.polarity\n",
    "    subj = blob.sentiment.subjectivity\n",
    "    pol_vec.append(pol)\n",
    "    subj_vec.append(subj)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'polarity': pol_vec, 'subjectivity': subj_vec}\n",
    "t = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e76be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = pd.concat([nyt,t], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f086e-f010-404f-8ef1-bd7373dfe60b",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2963563f-f76c-4fd2-a852-c213056f0340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "is_training = nyt['pub_date'] < pd.to_datetime( pm['start_date_test'], utc=True )\n",
    "is_test = np.invert( is_training )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e237b54-ed3f-45f6-8eb2-db6f9cd9d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt.loc[is_training].to_csv( '../data/train/media_{}_{}.csv'.format( pm['start_date'].date(), pm['start_date_train'].date() )\n",
    "nyt.loc[is_test].to_csv( '../data/test/media_{}_{}.csv'.format( pm['start_date_train'].date(), pm['end_date'].date() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597bf91-99d5-4656-8705-3f5e3aa971ca",
   "metadata": {},
   "source": [
    "# YFinance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5387d5f-8c13-438e-86b6-b89404d905c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be58460d-6b54-4d97-b64e-e7205641468d",
   "metadata": {},
   "source": [
    "## Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6e8ea-7997-4754-a470-cc6be7c64a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yticker = yf.Ticker( pm['ticker'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c8bbf-7dc4-4a98-81d9-e00831aba435",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = yticker.history(\n",
    "    start = pm['start_date'],\n",
    "    end = pm['end_date'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc33f8d-89e4-47d1-b563-ed4a01fb33cf",
   "metadata": {},
   "source": [
    "## Add an adjusted close column\n",
    "This more-closely tracks the actual stock value. In many cases it's identical to close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd14c59-a4f0-4a5a-b6e4-48d9e27dba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "history['AdjClose'] = history['Close'] - history['Dividends'] - history['Stock Splits']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29706816-0699-4359-82d3-2c36aa0c18b9",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4037086-85ec-46a4-a9d3-3ff146b98746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "is_training = history.index < pd.to_datetime( pm['start_date_test'], utc=True )\n",
    "is_test = np.invert( is_training )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58151287-4ddb-4bd1-bf71-38e102b8900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '../data/test/markets.csv'.format( history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f766d-ef1a-4f2d-baf4-16822a11d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.loc[is_training].to_csv( '../data/train/markets_{}_{}.csv'.format( pm['start_date'].date(), pm['start_date_train'].date() )\n",
    "history.loc[is_test].to_csv( '../data/test/markets_{}_{}.csv'.format( pm['start_date_train'].date(), pm['end_date'].date() ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
