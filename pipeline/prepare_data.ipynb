{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4e0a66-4373-46e1-9f71-a9ad93c432bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df70076-bc77-445b-9f00-2c292bdd89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the config file in the same directory as the analysis script\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1074de-f7b8-4748-b3f4-7cdf62bb64b4",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803fc9c-5b1d-49f5-b8bf-9b450a1b6217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters set in this notebook\n",
    "# If any of these are contained in the config they will be overwritten\n",
    "pm = {\n",
    "    # Max number of articles to retrieve\n",
    "    'n_articles': 100000,\n",
    "    \n",
    "    # We toss anything below these as irrelevant\n",
    "    'required_rank': 5,\n",
    "    'required_mentions': 0,\n",
    "    \n",
    "    # Columns from which to compile text\n",
    "    'text_columns': [ 'abstract', 'lead_paragraph', 'snippet', 'headline.main', ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18adc45-39c9-42d9-9efd-1f04beff4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update with global parameters\n",
    "pm.update( config.pm )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12100185-1f6b-414f-a299-4c5dd647ff48",
   "metadata": {},
   "source": [
    "# New York Times data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb1cec-87a1-4afa-bede-adfc61f4f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynytimes import NYTAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb734e26-200a-4f2e-92a5-d116f7e2f990",
   "metadata": {},
   "source": [
    "## Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f82e6d-e04f-4cf0-8107-e7ac37ec838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nytapi = NYTAPI( os.environ.get( 'NYTIMES_KEY' ), parse_dates=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce016f-faee-4ad9-b49c-491d44fe8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a prompt for the API\n",
    "filter_query_prompt = ''\n",
    "for i, organization in enumerate( pm['organizations'] ):\n",
    "    if i != 0:\n",
    "        filter_query_prompt += ' OR '\n",
    "    filter_query_prompt += 'organizations:(\"{}\")'.format( organization )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b53b17-cb58-4917-900c-85d6c72004d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all results\n",
    "all_results = nytapi.article_search(\n",
    "    query='',\n",
    "    results=pm['n_articles'],\n",
    "    dates={ 'begin':pm['start_date'], 'end':pm['end_date'] },\n",
    "    options={\n",
    "        'fq': filter_query_prompt,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7468a3-be14-458f-8c5d-f3f4d66bcbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Retrieved {} results'.format( len( all_results ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee387c0-d268-4c60-bef8-8435c12f854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter on organization rank\n",
    "results = []\n",
    "ranks = []\n",
    "for result in all_results:\n",
    "    \n",
    "    append_result = False\n",
    "    rank = np.inf\n",
    "    for keyword in result['keywords']:\n",
    "        is_relevant = (\n",
    "            ( keyword['value'] in pm['organizations'] )\n",
    "            and ( keyword['name'] == 'organizations' )\n",
    "            and ( keyword['rank'] <= pm['required_rank'] )\n",
    "        )\n",
    "        if is_relevant:\n",
    "            append_result = True\n",
    "\n",
    "            # Keep the lowest (most-relevant) rank\n",
    "            if keyword['rank'] < rank:\n",
    "                rank = keyword['rank']\n",
    "\n",
    "    if append_result:\n",
    "        results.append( result )\n",
    "        ranks.append( rank )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defcb52e-9b53-41ff-887b-ab8b7f4d66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Filtered down to {} retrieved results'.format( len( results ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3a5d7-56f2-49aa-9663-77dbcdee3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create storage dictionary\n",
    "nyt_data = {\n",
    "    'pub_date': [],\n",
    "    'word_count': [],\n",
    "    'type_of_material': [],\n",
    "    '_id': [],\n",
    "}\n",
    "for column in pm['text_columns']:\n",
    "    nyt_data[column] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504efb80-9884-42bf-b558-02b767e68ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect\n",
    "for i, result in enumerate( results ):\n",
    "    for column in nyt_data.keys():\n",
    "        \n",
    "        # Parse column\n",
    "        if '.' in column:\n",
    "            column_keys = column.split( '.' )\n",
    "            column_val = result[column_keys[0]][column_keys[1]]\n",
    "        else:\n",
    "            column_val = result[column]\n",
    "            \n",
    "        # Store\n",
    "        nyt_data[column].append( column_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0242f108-2667-488b-a92d-70f115d0317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into a dataframe\n",
    "nyt = pd.DataFrame( nyt_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c2561-8ebd-4d58-a114-2b0122ae51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the full string\n",
    "nyt['text'] = ( nyt[pm['text_columns']] + ' ' ).sum( axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec0b78-45b7-4cf6-a30a-280c3eb01de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store relvancy\n",
    "nyt['relevance_rank'] = ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca137ff-41e2-4bfb-93f9-7bc32353cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364b88d-83eb-43cd-9549-24a017688b88",
   "metadata": {},
   "source": [
    "## Filter Data\n",
    "Some of the text columns don't mention google *enough* times. This portion of the notebook removes those rows.\n",
    "\n",
    "We need to import the library in the cell below in order to use the word_count function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a23f01-b3f4-4ee4-9f92-661f5e1c8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcea7a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7615be-b8a7-4a16-acfd-ca949c00ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count keyword mentions\n",
    "inds_to_drop = []\n",
    "keyword_counts = []\n",
    "for i in range (len(nyt['text'])):\n",
    "    blob = TextBlob(nyt.loc[i,'text'])\n",
    "    keyword_count = blob.word_counts[pm['keyword']]\n",
    "    keyword_counts.append( keyword_count )\n",
    "    if keyword_count < pm['required_mentions']:\n",
    "        inds_to_drop.append( i )\n",
    "nyt['keyword_counts'] = keyword_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbbfbe1-20ea-4bcb-87c0-371077d3c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop keywords with an insufficient number of mentions\n",
    "nyt.drop( inds_to_drop, inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38011d69-cded-429c-994d-ac75d3d6e32e",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Using distilRoberta-financial-sentiment.\n",
    "See https://huggingface.co/mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f80973-c256-43d9-9293-b0b29117d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## initializing the new model and tokenizer\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer_fin = AutoTokenizer.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "\n",
    "model_fin = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dcbd9a-91a8-4a3c-997e-7650600037cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis pipeline with the new model and tokenizer\n",
    "from transformers import pipeline\n",
    "\n",
    "analyzer_fin = pipeline(\"sentiment-analysis\", model= model_fin , tokenizer = tokenizer_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726c239e-2a34-42c1-98dc-b7a2ed6d245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply analyzer_fin pipeline to the text of each article and recording the sentiment scores in a new column\n",
    "\n",
    "# initialize a list to store the sentiment scores\n",
    "sentiment_scores = []\n",
    "\n",
    "# loop through each article\n",
    "for text in nyt['text']:\n",
    "    # apply the sentiment analysis pipeline to the abstract\n",
    "    sentiment_scores.append(analyzer(text)[0].get('score'))\n",
    "    \n",
    "# add the sentiment scores to the media data\n",
    "nyt['NLP_fin-sentiment-text'] = sentiment_scores\n",
    "\n",
    "\n",
    "nyt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ffab6-6c01-4e7b-9acb-c7d47ddbc04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## looking at the articles with the highest and lowest NLP_fin-sentiment-text scores\n",
    "max_score = nyt['NLP_fin-sentiment-text'].max()\n",
    "min_score = nyt['NLP_fin-sentiment-text'].min()\n",
    "\n",
    "## display the articles with the highest and lowest nlp_sentiment_scores\n",
    "articles_with_max_score = nyt[nyt['NLP_fin-sentiment-text'] == max_score]\n",
    "articles_with_min_score = nyt[nyt['NLP_fin-sentiment-text'] == min_score]\n",
    "\n",
    "print(\"Article with the highest sentiment score was: \\n'{}' with score {}, \\n and the lowest sentiment score was: \\n'{}' with score {}\".format(articles_with_max_score['headline.main'].values[0], max_score, articles_with_min_score['headline.main'].values[0], min_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b36d4-3143-4ada-a9e4-6feaa7651a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot a distogram of the NLP_fin-sentiment-text column vs its frequency\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style( 'whitegrid' )\n",
    "\n",
    "# set the plot size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plot a histogram of the NLP_fin-sentiment-text column\n",
    "sns.distplot(nyt['NLP_fin-sentiment-text'])\n",
    "\n",
    "# set the title and labels\n",
    "plt.title('Histogram of NLP_fin sentiment score')\n",
    "plt.xlabel('NLP_fin sentiment score')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6c7dcf-0eed-42b3-ab79-827043504690",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adjusting the polarity scores to be between 0 and 1 (assume uniform distribution)\n",
    "\n",
    "# initialize a list to store the adjusted sentiment scores\n",
    "adjusted_polarity_scores = []\n",
    "\n",
    "# loop through each sentiment score\n",
    "for score in nyt['Polarity']:\n",
    "    # adjust the sentiment score\n",
    "    adjusted_polarity_scores.append((score + 1)/2)\n",
    "\n",
    "# add the adjusted sentiment scores to the media data\n",
    "nyt['adjusted_polarity'] = adjusted_polarity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f086e-f010-404f-8ef1-bd7373dfe60b",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2963563f-f76c-4fd2-a852-c213056f0340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "is_training = nyt['pub_date'] < pd.to_datetime( pm['start_date_test'], utc=True )\n",
    "is_test = np.invert( is_training )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e237b54-ed3f-45f6-8eb2-db6f9cd9d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt.loc[is_training].to_csv( '../data/train/media.csv' )\n",
    "nyt.loc[is_test].to_csv( '../data/test/media.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876ad41-2a65-4f25-b75d-8b30c1d0bc46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
